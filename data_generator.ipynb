{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data\n",
    "- Target: generate n (default n = 24) rows for each stay_id, with the following 30 columns\n",
    "    - baseline (9 cols): age, gender, insurance type, race, first care unit ICU, Admission type, Height, Weight, Tobacco\n",
    "    - ventilation (9 cols): peep, fio2, tidal_volume_observed, ~~O2 flow~~ (drop due to too many missing), respiratory_rate_set, Plateau pressure, RSBI: resp_rate / tidal_volume_observed, minute_ventilation: resp_rate * tidal_volume_observed, ventilator_mode, ventilator_mode_group\n",
    "    - vitalsign (6 cols): heart_rate, sbp, dbp, mbp, spO2, resp_rate\n",
    "    - id_info (6 cols): subject_id, stay_id, hadm_id, charttime, before_weaning_hr, label\n",
    "- Baseline features steps:\n",
    "    1. Read in data\n",
    "    2. Merge with ground truth (\"label\")\n",
    "    3. Show tableone for the Baseline features with missing value and outliers\n",
    "    4. Use KNN for the missing value on weight and height\n",
    "    5. Deal with outlier by 3 std as boundary\n",
    "    6. Show tableone for the Baseline features after deal with outliers\n",
    "- Charttime featrues steps:\n",
    "    1. Round the charttime to hour\n",
    "    2. Filter the charttime data start / end from ventilation starttime / endtime within 24 hr\n",
    "    3. Fill the missing value forward then backward by stay_id by each of the charttime df (ventilator_setting_df, vitalsign_df, labevents_df)\n",
    "    4. Generate template: n rows for each stay_id, # of total rows = n * # of stay_id\n",
    "    5. Merge template with charttime dataframes (left join): some hour might be empty, while some hour might have more than one rows\n",
    "    6. Fill the missing value again (some missing value might appear when step 5. merge into 24 rows)\n",
    "    7. Use aggregation function dealing with \"one hour with multiple line\" (e.g., vitalsign: one hour have two records -> merge into one row)\n",
    "    8. Calculate 'RSBI' and 'minute_ventilation' by 'tidal_volume_observed' and 'resp_rate'\n",
    "    9. Merge with ground truth (\"label\")\n",
    "    10. Show tableone for the Charttime features with missing value and outliers\n",
    "    11. Deal with outlier by 3 std as boundary\n",
    "    12. Show tableone for the Baseline features after deal with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.impute import KNNImputer\n",
    "from tableone import TableOne, load_dataset\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = pd.read_csv(\"data/data_by_table/baseline.csv\")\n",
    "ventilator_setting_df = pd.read_csv(\"data/data_by_table/mimiciv_derived_ventilator_setting.csv\")\n",
    "vitalsign_df = pd.read_csv(\"data/data_by_table/mimiciv_derived_vitalsign.csv\")\n",
    "# labevents_df = pd.read_csv(\"data/data_by_table/mimiciv_hosp_labevents.csv\")\n",
    "labevents_df = pd.read_csv(\"data/data_by_table/mimiciv_hosp_labevents_itemid_50821.csv\")\n",
    "cohort_subject_id_stay_id_df = pd.read_csv(\"data/data_by_table/cohort_subject_id_stay_id.csv\")\n",
    "ground_truth_df = pd.read_csv(\"data/data_by_table/ground_truth.csv\")\n",
    "labevents_df['O2_flow'].replace('___', pd.NA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with ground truth (\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_gt_df = pd.merge(baseline_df, ground_truth_df[[\"stay_id\", \"label\"]], on = [\"stay_id\"], how = \"inner\")\n",
    "baseline_gt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show tableone for the Baseline features with missing value and outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['age_now', 'gender', 'insurance', 'admission_type',\n",
    "                'first_careunit', 'weight_kg', 'height_cm', 'tobacco', 'label'] # 'race'\n",
    "categorical = ['gender', 'insurance', 'admission_type', 'first_careunit']   # 'race'\n",
    "groupby = ['label']\n",
    "table_with_outlier = TableOne(baseline_gt_df, columns=features_col, categorical=categorical, groupby=groupby, pval=True)\n",
    "table_with_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['race', 'label']\n",
    "categorical = ['race']   # 'race'\n",
    "groupby = ['label']\n",
    "table_with_outlier = TableOne(baseline_gt_df, columns=features_col, categorical=categorical, groupby=groupby, pval=True)\n",
    "table_with_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use KNN for the missing value on weight and height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_weight_height(baseline_gt_df):\n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    baseline_gt_df[['height_cm', 'weight_kg']] = imputer.fit_transform(baseline_gt_df[['height_cm', 'weight_kg']])\n",
    "    baseline_gt_df['height_cm'].fillna(baseline_gt_df.groupby('gender')['height_cm'].transform('mean'), inplace=True)\n",
    "    baseline_gt_df['weight_kg'].fillna(baseline_gt_df.groupby('gender')['weight_kg'].transform('mean'), inplace=True)\n",
    "    return baseline_gt_df\n",
    "    # baseline_df_p.drop(columns=['subject_id', 'hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_fill_w_h_df = KNN_weight_height(baseline_gt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['weight_kg', 'height_cm', 'label']\n",
    "categorical = []\n",
    "groupby = ['label']\n",
    "table_with_outlier = TableOne(baseline_fill_w_h_df, columns=features_col, categorical=categorical, groupby=groupby, pval=True)\n",
    "table_with_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with outlier by 3 std as boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(series, threshold=3):\n",
    "    lower_bound = series.quantile(0.25) - threshold * (series.quantile(0.75) - series.quantile(0.25))\n",
    "    upper_bound = series.quantile(0.75) + threshold * (series.quantile(0.75) - series.quantile(0.25))\n",
    "    # print(f'upper_bound: {upper_bound}\\n lower_bound: {lower_bound}')\n",
    "    # print(series[series < lower_bound])\n",
    "    # print(series[series > upper_bound])\n",
    "    series[series < lower_bound] = lower_bound\n",
    "    series[series > upper_bound] = upper_bound\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = baseline_fill_w_h_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "numeric_columns = numeric_columns.drop([\"stay_id\", \"subject_id\", 'hadm_id', 'age_now', 'tobacco', 'label'])\n",
    "# Apply the function to each numeric column\n",
    "baseline_fill_w_h_df[numeric_columns] = baseline_fill_w_h_df[numeric_columns].apply(handle_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show tableone for the Baseline features after deal with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['weight_kg', 'height_cm', 'label']\n",
    "categorical = []\n",
    "groupby = ['label']\n",
    "table_without_outlier = TableOne(baseline_fill_w_h_df, columns=features_col, categorical=categorical, groupby=groupby, pval=True)\n",
    "table_without_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chattime features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round the charttime to hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_hour(charttime_df):\n",
    "    charttime_df['charttime'] = pd.to_datetime(charttime_df['charttime']).dt.round('H')\n",
    "    return charttime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventilator_setting_round_df = round_hour(ventilator_setting_df)\n",
    "vitalsign_round_df = round_hour(vitalsign_df)\n",
    "labevents_round_df = round_hour(labevents_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the charttime data start / end from ventilation starttime / endtime within 24 hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_starttime_endtime(ground_truth_df, charttime_df, filter_hours):\n",
    "    filter_starttime_endtime_df = pd.DataFrame()\n",
    "    for index, row in ground_truth_df.iterrows():\n",
    "        start_time = pd.to_datetime(row['starttime']) - timedelta(hours=filter_hours)\n",
    "        end_time = pd.to_datetime(row['endtime']) + timedelta(hours=filter_hours)\n",
    "        stay_id = row['stay_id']\n",
    "        df_subset = charttime_df[(charttime_df['stay_id'] == stay_id) & (charttime_df['charttime'] >= start_time) & (charttime_df['charttime'] <= end_time)]\n",
    "        filter_starttime_endtime_df = pd.concat([filter_starttime_endtime_df, df_subset])\n",
    "    return filter_starttime_endtime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ventilator_setting_df))\n",
    "print(len(vitalsign_df))\n",
    "print(len(labevents_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_hours = 24\n",
    "ventilator_setting_filter_df = filter_starttime_endtime(ground_truth_df, ventilator_setting_round_df, filter_hours)\n",
    "vitalsign_filter_df = filter_starttime_endtime(ground_truth_df, vitalsign_round_df, filter_hours)\n",
    "labevents_filter_df = filter_starttime_endtime(ground_truth_df, labevents_round_df, filter_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ventilator_setting_filter_df))\n",
    "print(len(vitalsign_filter_df))\n",
    "print(len(labevents_filter_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_hours = 0\n",
    "ventilator_setting_filter_0_df = filter_starttime_endtime(ground_truth_df, ventilator_setting_filter_df, filter_hours)\n",
    "vitalsign_filter_0_df = filter_starttime_endtime(ground_truth_df, vitalsign_filter_df, filter_hours)\n",
    "labevents_filter_0_df = filter_starttime_endtime(ground_truth_df, labevents_filter_df, filter_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ventilator_setting_filter_0_df))\n",
    "print(len(vitalsign_filter_0_df))\n",
    "print(len(labevents_filter_0_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the missing value forward then backward by stay_id by each of the charttime df (ventilator_setting_df, vitalsign_df, labevents_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_Nan(df):\n",
    "    # Convert 'charttime' to datetime format for sorting\n",
    "    df['charttime'] = pd.to_datetime(df['charttime'])\n",
    "    # Sort DataFrame by 'stay_id' and 'charttime'\n",
    "    df.sort_values(by=['stay_id', 'charttime'], inplace=True)\n",
    "    # Fill NaN values within each 'stay_id' using forward-fill and backward-fill\n",
    "    df = df.groupby('stay_id').apply(lambda group: group.ffill().bfill())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventilator_setting_fill_df = fill_Nan(ventilator_setting_filter_df)\n",
    "vitalsign_fill_df = fill_Nan(vitalsign_filter_df)\n",
    "labevents_fill_df = fill_Nan(labevents_filter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate template: n rows for each stay_id, # of total rows = n * # of stay_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df_template(stay_id, endtime):\n",
    "    end_time = pd.to_datetime(endtime).floor('H')\n",
    "    time_intervals = [end_time - timedelta(hours=i) for i in range(24)]\n",
    "    df = pd.DataFrame(time_intervals, columns=['charttime'])\n",
    "    df['stay_id'] = stay_id \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_template(ground_truth_df):\n",
    "    data_template = pd.DataFrame()\n",
    "    for index, row in ground_truth_df.iterrows():\n",
    "        data_now = generate_df_template(row['stay_id'],row['endtime'])\n",
    "        data_template = pd.concat([data_template, data_now], ignore_index=False)\n",
    "    return data_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_template = generate_all_template(ground_truth_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge template with charttime dataframes (left join): some hour might be empty, while some hour might have more than one rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(data_template, charttime_dfs):\n",
    "    for df in charttime_dfs:\n",
    "        df = df.drop(columns=[\"subject_id\"])\n",
    "        data_template = pd.merge(data_template, df, on=[\"stay_id\", \"charttime\"], how=\"left\")\n",
    "    return data_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_charttime_df = merge_dfs(data_template, [ventilator_setting_fill_df, vitalsign_fill_df, labevents_fill_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the missing value again (some missing value might appear when step 5. merge into 24 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_charttime_fill_df = fill_Nan(merge_charttime_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter endtime previous 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pre_24_hr(ground_truth_df, charttime_df):\n",
    "    pre_24_hr_df = pd.DataFrame()\n",
    "    for index, row in ground_truth_df.iterrows():\n",
    "        start_time = pd.to_datetime(row['endtime']) - timedelta(hours=24)\n",
    "        end_time = pd.to_datetime(row['endtime'])\n",
    "        stay_id = row['stay_id']\n",
    "        df_subset = charttime_df[(charttime_df['stay_id'] == stay_id) & (charttime_df['charttime'] > start_time) & (charttime_df['charttime'] <= end_time)] # TODO: not sure < or <= end_time\n",
    "        pre_24_hr_df = pd.concat([pre_24_hr_df, df_subset])\n",
    "    return pre_24_hr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_pre_24_hr_df = filter_pre_24_hr(ground_truth_df, merge_charttime_fill_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use aggregation function dealing with \"one hour with multiple line\" (e.g., vitalsign: one hour have two records -> merge into one row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_weaning_hr(df):\n",
    "    # Assuming your DataFrame is named df\n",
    "    df['charttime'] = pd.to_datetime(df['charttime'])  # Convert to datetime if not already\n",
    "    df.sort_values(['stay_id', 'charttime'], inplace=True)  # Sort by stay_id and charttime\n",
    "\n",
    "    # Calculate the 'before_weaning_hr' column\n",
    "    df['before_weaning_hr'] = df.groupby('stay_id').cumcount(ascending=False)\n",
    "def min_agg(series):\n",
    "    non_nan_values = series.dropna()\n",
    "    if len(non_nan_values) == 0:\n",
    "        return np.nan  # No values available, keep it as NaN\n",
    "    else:\n",
    "        return non_nan_values.min()  # Choose the minimum value among available values\n",
    "def max_agg(series):\n",
    "    non_nan_values = series.dropna()\n",
    "    if len(non_nan_values) == 0:\n",
    "        return np.nan  # No values available, keep it as NaN\n",
    "    else:\n",
    "        return non_nan_values.max()  # Choose the maximum value among available values\n",
    "def HR_agg(series): # this rule is by Dr.\n",
    "    # Rule 1: If all records are greater than or equal to 80, return the max\n",
    "    if all(value >= 80 for value in series):\n",
    "        return series.max()\n",
    "    # Rule 2: If all records are less than 80, return the min\n",
    "    elif all(value < 80 for value in series):\n",
    "        return series.min()\n",
    "    # Rule 3: Otherwise, return the min\n",
    "    else:\n",
    "        return series.min()\n",
    "def RR_agg(series): # this rule is by Dr.\n",
    "    # Rule 1: If all records are greater than or equal to 12, return the max\n",
    "    if all(value >= 12 for value in series):\n",
    "        return series.max()\n",
    "    # Rule 2: If all records are less than 12, return the min\n",
    "    elif all(value < 12 for value in series):\n",
    "        return series.min()\n",
    "    # Rule 3: Otherwise, return the min\n",
    "    else:\n",
    "        return series.min()\n",
    "\n",
    "def flat_to_24_rows(pre_24_hr_df):\n",
    "    # Apply the custom aggregation function for each feature\n",
    "    pre_24_rows_df = pre_24_hr_df.groupby(['stay_id', 'charttime']).agg({\n",
    "        'peep': max_agg,\n",
    "        'fio2': max_agg,\n",
    "        'tidal_volume_observed': max_agg,\n",
    "        'respiratory_rate_set': max_agg,\n",
    "        'plateau_pressure': max_agg,\n",
    "        'heart_rate': HR_agg,\n",
    "        'sbp': min_agg,\n",
    "        'dbp': min_agg,\n",
    "        'mbp': min_agg,\n",
    "        'resp_rate': RR_agg,\n",
    "        'spo2': min_agg,\n",
    "        'O2_flow': max_agg,\n",
    "        'ventilator_mode': 'first'\n",
    "    }).reset_index()\n",
    "    before_weaning_hr(pre_24_rows_df)\n",
    "    return pre_24_rows_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_24_rows_df = flat_to_24_rows(filter_pre_24_hr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate 'RSBI' and 'minute_ventilation' by 'tidal_volume_observed' and 'resp_rate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_ventilator_mode(ventilator_mode):\n",
    "    complete_support = [\"PRVC/AC\", \"PCV+Assist\", \"PCV+\", \"MMV/AutoFlow\", \"APRV\", \"CMV/AutoFlow\",\n",
    "                        \"CMV\", \"PRES/AC (PCAC)\", \"APV (cmv)\", \"PRVC/SIMV (=aprv)\", \"MMV\",\n",
    "                        \"VOL/AC\", \"APRV/Biphasic+ApnVol\", \"APRV/Biphasic+ApnPress\", \"(S) CMV\",\n",
    "                        \"P-CMV\", \"CMV/ASSIST\", \"MMV/PSV/AutoFlow\", \"CMV/ASSIST/AutoFlow\"]\n",
    "\n",
    "    partial_support = [\"SIMV/PSV/AutoFlow\", \"SIMV/PRES\", \"SIMV/PSV\", \"SIMV/AutoFlow\", \"SIMV/VOL\",\n",
    "                       \"SIMV\", \"SYNCHRON MASTER\", \"SYNCHRON SLAVE\"]\n",
    "\n",
    "    minimal_support = [\"CPAP/PSV+ApnVol\", \"CPAP/PPS\", \"PCV+/PSV\", \"Apnea Ventilation\", \"CPAP\",\n",
    "                       \"MMV/PSV\", \"SPONT\", \"CPAP/PSV+ApnPres\", \"Ambient\", \"CPAP/PSV+Apn TCPL(time cycle pressure limit)\",\n",
    "                       \"null\", \"PSV/SBT\", \"Standby\", \"CPAP/PSV\"]\n",
    "\n",
    "    if ventilator_mode in complete_support:\n",
    "        return \"Complete Support\"\n",
    "    elif ventilator_mode in partial_support:\n",
    "        return \"Partial Support\"\n",
    "    elif ventilator_mode in minimal_support:\n",
    "        return \"Minimal Support\"\n",
    "    else:\n",
    "        return \"Minimal Support\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_24_rows_df['RSBI'] = pre_24_rows_df['resp_rate'] / (pre_24_rows_df['tidal_volume_observed'] * 0.001)\n",
    "pre_24_rows_df['minute_ventilation'] = pre_24_rows_df['resp_rate'] * (pre_24_rows_df['tidal_volume_observed'] * 0.001)\n",
    "# Apply the categorization function to create the new column\n",
    "pre_24_rows_df['ventilator_mode_group'] = pre_24_rows_df['ventilator_mode'].apply(categorize_ventilator_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_24_rows_df[pre_24_rows_df[\"ventilator_mode_group\"] == \"Minimal Support\"]\n",
    "pre_24_rows_df[pre_24_rows_df[\"RSBI\"] > 105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with ground truth (\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_24_rows_gt_df = pd.merge(pre_24_rows_df, ground_truth_df[[\"stay_id\", \"label\"]], on=[\"stay_id\"], how=\"inner\")\n",
    "pre_24_rows_gt_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_24_rows_gt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show tableone for the Charttime features with missing value and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['peep', 'fio2', 'tidal_volume_observed', 'respiratory_rate_set', \n",
    "                'plateau_pressure', 'heart_rate', 'sbp', 'dbp', 'mbp', \n",
    "                'resp_rate', 'spo2', 'O2_flow', 'RSBI', 'minute_ventilation', 'label']\n",
    "categorical = []\n",
    "groupby = ['label']\n",
    "table_with_outlier = TableOne(pre_24_rows_gt_df, columns=features_col, categorical=categorical, groupby=groupby, pval=True)\n",
    "table_with_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization for the outliers obervation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming pre_24_rows_gt_df is your DataFrame\n",
    "# Drop non-numeric columns for simplicity in the example\n",
    "numeric_cols = pre_24_rows_gt_df.select_dtypes(include='number').columns\n",
    "\n",
    "# Set up subplots\n",
    "fig, axes = plt.subplots(nrows=len(numeric_cols), ncols=1, figsize=(10, 5 * len(numeric_cols)))\n",
    "\n",
    "# Iterate through numeric columns and create histograms\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    sns.histplot(pre_24_rows_gt_df[col], kde=True, ax=axes[i])\n",
    "    \n",
    "    # Calculate 75th percentile and 25th percentile\n",
    "    p75 = pre_24_rows_gt_df[col].quantile(0.75)\n",
    "    p25 = pre_24_rows_gt_df[col].quantile(0.25)\n",
    "    \n",
    "    # Calculate upper and lower bounds for outliers\n",
    "    upper_bound = p75 + 3 * pre_24_rows_gt_df[col].std()\n",
    "    lower_bound = p25 - 3 * pre_24_rows_gt_df[col].std()\n",
    "    \n",
    "    # Add lines for upper and lower bounds\n",
    "    axes[i].axvline(upper_bound, color='red', linestyle='dashed', label='Upper Bound')\n",
    "    axes[i].axvline(lower_bound, color='orange', linestyle='dashed', label='Lower Bound')\n",
    "    \n",
    "    axes[i].set_title(f'Histogram of {col}')\n",
    "    axes[i].legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming pre_24_rows_gt_df is your DataFrame\n",
    "column_stats = pre_24_rows_gt_df.describe(include='all')\n",
    "\n",
    "# Print mean, std, min, and max for each column\n",
    "for col in pre_24_rows_gt_df.columns:\n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"Mean: {column_stats.loc['mean', col]}\")\n",
    "    print(f\"Std: {column_stats.loc['std', col]}\")\n",
    "    print(f\"Min: {column_stats.loc['min', col]}\")\n",
    "    print(f\"Max: {column_stats.loc['max', col]}\")\n",
    "    # Calculate and print 3 std + 75% and 25% - 3 std\n",
    "    upper_limit = column_stats.loc['75%', col] + 3 * column_stats.loc['std', col]\n",
    "    lower_limit = column_stats.loc['25%', col] - 3 * column_stats.loc['std', col]\n",
    "    print(f\"75% + 3 Std: {upper_limit}\")\n",
    "    print(f\"25% - 3 Std: {lower_limit}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with outlier by costum boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outliers(df, reasonable_ranges, outlier_threshold=3):\n",
    "    for feature, (lower_limit, upper_limit) in reasonable_ranges.items():\n",
    "        # Filter outliers for each feature based on the specified range\n",
    "        feature_outliers = (\n",
    "            (df[feature] < lower_limit) | (df[feature] > upper_limit)\n",
    "        )\n",
    "        \n",
    "        # Replace outliers with NaN in the original DataFrame\n",
    "        df.loc[feature_outliers, feature] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example of setting reasonable ranges\n",
    "reasonable_ranges = {\n",
    "    'peep': (0, 20),\n",
    "    'fio2': (0, 100),\n",
    "    'tidal_volume_observed': (0, 1250),\n",
    "    'respiratory_rate_set': (0, 50),\n",
    "    'plateau_pressure': (0, 40),\n",
    "    'heart_rate': (25, 216),\n",
    "    'sbp': (15, 252),\n",
    "    'dbp': (10, 247),\n",
    "    'mbp': (1, 298),\n",
    "    'resp_rate': (1, 68),\n",
    "    'spo2': (2, 100),\n",
    "    'O2_flow': (60, 576),\n",
    "    'before_weaning_hr': (0, 23),\n",
    "}\n",
    "\n",
    "# Example usage\n",
    "pre_24_rows_gt_filter_df= filter_outliers(pre_24_rows_gt_df, reasonable_ranges)\n",
    "pre_24_rows_gt_fill_df = fill_Nan(pre_24_rows_gt_filter_df)\n",
    "# Display filtered DataFrame and outliers DataFrame\n",
    "print(\"Filtered DataFrame:\")\n",
    "pre_24_rows_gt_fill_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recalculate 'RSBI' and 'minute_ventilation' after dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_24_rows_gt_fill_df['RSBI'] = pre_24_rows_gt_fill_df['resp_rate'] / (pre_24_rows_gt_fill_df['tidal_volume_observed'] * 0.001)\n",
    "pre_24_rows_gt_fill_df['minute_ventilation'] = pre_24_rows_gt_fill_df['resp_rate'] * (pre_24_rows_gt_fill_df['tidal_volume_observed'] * 0.001)\n",
    "# Apply the categorization function to create the new column\n",
    "pre_24_rows_gt_fill_df['ventilator_mode_group'] = pre_24_rows_gt_fill_df['ventilator_mode'].apply(categorize_ventilator_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill with outliers(inf) as by ffill and bfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_24_rows_gt_fill_df['RSBI'] = pre_24_rows_gt_fill_df['RSBI'].replace(np.inf, np.nan)\n",
    "pre_24_rows_gt_fill_df = fill_Nan(pre_24_rows_gt_fill_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_24_rows_gt_fill_df[pre_24_rows_gt_fill_df['stay_id'] == 30109194]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show tableone for the Baseline features after dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['peep', 'fio2', 'tidal_volume_observed', 'respiratory_rate_set', \n",
    "                'plateau_pressure', 'heart_rate', 'sbp', 'dbp', 'mbp', \n",
    "                'resp_rate', 'spo2', 'O2_flow', 'RSBI', 'minute_ventilation', 'label']\n",
    "categorical = []\n",
    "groupby = ['label']\n",
    "table_without_outlier = TableOne(pre_24_rows_gt_fill_df, columns=features_col, categorical=categorical, groupby=groupby, pval=True)\n",
    "table_without_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quick look at missing val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_for_miss = \"respiratory_rate_set\" # you can change this for quick look at the missing (0 records for the raw data)\n",
    "# Count occurrences of 0 in feature_for_miss for each \"stay_id\"\n",
    "counts = ventilator_setting_df[[\"stay_id\", feature_for_miss]].groupby(\"stay_id\").count()\n",
    "\n",
    "# Count how many stay_id have count of 0 for feature_for_miss\n",
    "zero_count_stay_id = (counts[feature_for_miss] == 0).sum()\n",
    "\n",
    "# Display the result\n",
    "print(\"Number of stay_id with count of 0 for respiratory_rate_set:\", zero_count_stay_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_24_rows_gt_fill_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge features to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_24_rows_merged = pd.merge(pre_24_rows_gt_fill_df, baseline_fill_w_h_df, on=[\"stay_id\", \"label\"], how=\"inner\")\n",
    "pre_24_rows_merged.drop('O2_flow', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop those having missing for all 24 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_24_rows_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify stay_ids with missing values\n",
    "stay_ids_with_missing_values = pre_24_rows_merged.loc[pre_24_rows_merged.isnull().any(axis=1), 'stay_id'].unique()\n",
    "\n",
    "# Create a DataFrame to store dropped rows\n",
    "drop_df = pre_24_rows_merged[pre_24_rows_merged['stay_id'].isin(stay_ids_with_missing_values)].copy()\n",
    "\n",
    "# Drop all records with specified stay_ids\n",
    "pre_24_rows_merged_without_miss = pre_24_rows_merged[~pre_24_rows_merged['stay_id'].isin(stay_ids_with_missing_values)]\n",
    "\n",
    "# Display or further process drop_df and pre_24_rows_merged_without_miss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['RSBI', 'minute_ventilation', 'ventilator_mode_group', 'peep', 'fio2', 'tidal_volume_observed', 'respiratory_rate_set', 'plateau_pressure', 'heart_rate', 'sbp', 'dbp', 'mbp', 'resp_rate', 'spo2', 'label']\n",
    "categorical = ['ventilator_mode_group']\n",
    "groupby = ['label']\n",
    "table_without_miss_and_outlier = TableOne(pre_24_rows_merged_without_miss, columns=features_col, categorical=categorical, groupby=groupby, pval=True)\n",
    "table_without_miss_and_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['subject_id', 'stay_id', 'hadm_id', 'charttime', 'before_weaning_hr', 'age_now', 'gender', 'insurance', 'race', 'first_careunit', 'admission_type', 'weight_kg', 'height_cm', 'tobacco', 'RSBI', 'minute_ventilation', 'ventilator_mode', 'ventilator_mode_group', 'peep', 'fio2', 'tidal_volume_observed', 'respiratory_rate_set', 'plateau_pressure', 'heart_rate', 'sbp', 'dbp', 'mbp', 'resp_rate', 'spo2', 'label']\n",
    "len(column_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the DataFrame based on the desired column order\n",
    "pre_24_rows_merged_ordered = pre_24_rows_merged_without_miss[column_order]\n",
    "pre_24_rows_merged_ordered.to_csv(\"data/data_by_table/pre_24_merged_30_rows_12_07.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take a look at the last hour, whether the std is smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hr_df = pre_24_rows_merged_ordered[pre_24_rows_merged_ordered[\"before_weaning_hr\"] == 0]\n",
    "first_hr_df = pre_24_rows_merged_ordered[pre_24_rows_merged_ordered[\"before_weaning_hr\"] == 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['RSBI', 'minute_ventilation', 'ventilator_mode_group', 'peep', 'fio2', 'tidal_volume_observed', 'respiratory_rate_set', 'plateau_pressure', 'heart_rate', 'sbp', 'dbp', 'mbp', 'resp_rate', 'spo2', 'label']\n",
    "categorical = ['ventilator_mode_group']\n",
    "groupby = ['label']\n",
    "table_done = TableOne(pre_24_rows_merged_ordered, columns=features_col, categorical=categorical, groupby=groupby, pval=True)\n",
    "table_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['RSBI', 'minute_ventilation', 'ventilator_mode_group', 'peep', 'fio2', 'tidal_volume_observed', 'respiratory_rate_set', 'plateau_pressure', 'heart_rate', 'sbp', 'dbp', 'mbp', 'resp_rate', 'spo2', 'label']\n",
    "categorical = ['ventilator_mode_group']\n",
    "groupby = ['label']\n",
    "table_done_last_hr = TableOne(last_hr_df, columns=features_col, categorical=categorical, groupby=groupby, pval=True)\n",
    "table_done_last_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['peep', 'fio2', 'respiratory_rate_set', 'plateau_pressure', 'ventilator_mode_group', 'heart_rate', 'sbp', 'dbp', 'mbp', 'resp_rate', 'spo2', 'tidal_volume_observed', 'RSBI', 'minute_ventilation', 'label']\n",
    "categorical = ['ventilator_mode_group']\n",
    "groupby = ['label']\n",
    "table_done_last_hr = TableOne(last_hr_df, columns=features_col, categorical=categorical, groupby=groupby, pval=True)\n",
    "table_done_last_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['RSBI', 'minute_ventilation', 'ventilator_mode_group', 'peep', 'fio2', 'tidal_volume_observed', 'respiratory_rate_set', 'plateau_pressure', 'heart_rate', 'sbp', 'dbp', 'mbp', 'resp_rate', 'spo2', 'label']\n",
    "categorical = ['ventilator_mode_group']\n",
    "groupby = ['label']\n",
    "table_done_first_hr = TableOne(first_hr_df, columns=features_col, categorical=categorical, groupby=groupby, pval=True)\n",
    "table_done_first_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['peep', 'fio2', 'respiratory_rate_set', 'plateau_pressure', 'ventilator_mode_group', 'heart_rate', 'sbp', 'dbp', 'mbp', 'resp_rate', 'spo2', 'tidal_volume_observed', 'RSBI', 'minute_ventilation', 'label']\n",
    "categorical = ['ventilator_mode_group']\n",
    "groupby = ['label']\n",
    "table_done_first_hr = TableOne(first_hr_df, columns=features_col, categorical=categorical, groupby=groupby, pval=True)\n",
    "table_done_first_hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jerry data for tableone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_24h_data_v4_df = pd.read_csv(\"data/data_by_table/pre_24h_data_v4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_24h_data_v4_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['peep', 'fio2', 'respiratory_rate_set', 'plateau_pressure', 'heart_rate', 'sbp', 'dbp', 'mbp', 'resp_rate', 'spo2', 'tidal_volume_observed', 'label']\n",
    "categorical = []\n",
    "groupby = ['label']\n",
    "table_done_first_hr = TableOne(pre_24h_data_v4_df, columns=features_col, categorical=categorical, groupby=groupby, pval=True)\n",
    "table_done_first_hr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
